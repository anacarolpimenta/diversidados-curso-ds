{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs=None, min_leaf=2):\n",
    "        if idxs is None: idxs = np.arange(len(y))\n",
    "        self.x, self.y, self.idxs, self.min_leaf = x, y, idxs, min_leaf\n",
    "        self.n, self.c = len(idxs), x.shape[1]\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()\n",
    "\n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c): self.find_better_split(i)\n",
    "        if self.score == float('inf'): return\n",
    "        x = self.split_col\n",
    "        lhs = np.nonzero(x <= self.split)[0]\n",
    "        rhs = np.nonzero(x > self.split)[0]\n",
    "        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "\n",
    "    def find_better_split(self, var_idx):\n",
    "        x, y = self.x.values[self.idxs, var_idx], self.y[self.idxs]\n",
    "        sort_idx = np.argsort(x)\n",
    "        sort_y, sort_x = y[sort_idx], x[sort_idx]\n",
    "        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y ** 2).sum()\n",
    "        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n",
    "\n",
    "        for i in range(0, self.n - self.min_leaf - 1):\n",
    "            xi, yi = sort_x[i], sort_y[i]\n",
    "            lhs_cnt += 1;\n",
    "            rhs_cnt -= 1\n",
    "            lhs_sum += yi;\n",
    "            rhs_sum -= yi\n",
    "            lhs_sum2 += yi ** 2;\n",
    "            rhs_sum2 -= yi ** 2\n",
    "            if i < self.min_leaf or xi == sort_x[i + 1]:\n",
    "                continue\n",
    "\n",
    "            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n",
    "            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n",
    "            curr_score = lhs_std * lhs_cnt + rhs_std * rhs_cnt\n",
    "            if curr_score < self.score:\n",
    "                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n",
    "\n",
    "    @property\n",
    "    def split_name(self):\n",
    "        return self.x.columns[self.var_idx]\n",
    "\n",
    "    @property\n",
    "    def split_col(self):\n",
    "        return self.x.values[self.idxs, self.var_idx]\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.score == float('inf')\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = f'n: {self.n}; val:{self.val}'\n",
    "        if not self.is_leaf:\n",
    "            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n",
    "        return s\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.array([self.predict_row(xi) for xi in x])\n",
    "\n",
    "    def predict_row(self, xi):\n",
    "        if self.is_leaf: return self.val\n",
    "        t = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n",
    "        return t.predict_row(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shap\n",
    "import matplotlib.pylab as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,50)\n",
    "x = pd.DataFrame({'x':x})\n",
    "\n",
    "y1 = np.random.uniform(10,15,10)\n",
    "y2 = np.random.uniform(20,25,10)\n",
    "y3 = np.random.uniform(0,5,10)\n",
    "y4 = np.random.uniform(30,32,10)\n",
    "y5 = np.random.uniform(13,17,10)\n",
    "\n",
    "y = np.concatenate((y1,y2,y3,y4,y5))\n",
    "y = y[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y, 'o')\n",
    "plt.title(\"x vs. y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem Fraca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nossa árvore de decisão encontra o melhor jeito de dividir o dataset em dois grupos, usando o método `find_better_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predf = 0\n",
    "\n",
    "tree = DecisionTree(x,y)\n",
    "tree.find_better_split(0)\n",
    "r = np.where(x == tree.split)[0][0]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(sharey=True, figsize = (13,5))\n",
    "ax.plot(x, y, 'o')\n",
    "ax.set_title(f'Divisão da Árvore de Decisão')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.axvline(r, c=\"k\", ls=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada um dos dois grupos o nosso _weak learner_ prevê encontra a média dos elementos. O processo pode ser repetido, a partir dos residuos desse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "\n",
    "left_idx = np.where(x <= tree.split)[0]\n",
    "right_idx = np.where(x > tree.split)[0]\n",
    "\n",
    "predi = np.zeros(n)\n",
    "np.put(predi, left_idx, np.repeat(np.mean(y[left_idx]), r))\n",
    "np.put(predi, right_idx, np.repeat(np.mean(y[right_idx]), n-r))\n",
    "\n",
    "predi = predi[:,None]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (20,5))\n",
    "ax1.plot(x, y, 'o')\n",
    "ax1.plot(x, predi, c=\"k\", ls=\"--\")\n",
    "ax1.set_title(f'Weak Learner')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.axvline(r, c=\"k\", ls=\"--\")\n",
    "\n",
    "\n",
    "tree = DecisionTree(x,y - predi)\n",
    "tree.find_better_split(0)\n",
    "r = np.where(x == tree.split)[0][0]\n",
    "\n",
    "ax2.plot(x, y - predi, 'o')\n",
    "ax2.set_title(f'Residuos (repete-se o processo)')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Residuo')\n",
    "ax2.axvline(r, c=\"k\", ls=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = x\n",
    "yi = y\n",
    "ei = 0\n",
    "n = len(yi)\n",
    "predf = 0\n",
    "\n",
    "for i in range(2):\n",
    "    tree = DecisionTree(xi,yi)\n",
    "    tree.find_better_split(0)\n",
    "    \n",
    "    r = np.where(xi == tree.split)[0][0]    \n",
    "    \n",
    "    left_idx = np.where(xi <= tree.split)[0]\n",
    "    right_idx = np.where(xi > tree.split)[0]\n",
    "    \n",
    "    predi = np.zeros(n)\n",
    "    np.put(predi, left_idx, np.repeat(np.mean(yi[left_idx]), r))\n",
    "    np.put(predi, right_idx, np.repeat(np.mean(yi[right_idx]), n-r))\n",
    "    \n",
    "    predi = predi[:,None]\n",
    "    predf = predf + predi\n",
    "    \n",
    "    ei = y - predf\n",
    "    yi = ei\n",
    "    \n",
    "    \n",
    "    xa = np.array(x.x) \n",
    "    order = np.argsort(xa)\n",
    "    xs = np.array(xa)[order]\n",
    "    ys = np.array(predf)[order]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize = (18,3.5))\n",
    "\n",
    "    ax1.plot(x, y - (predf - predi), 'go')\n",
    "    ax1.plot(x, predi, 'g', ls=\"--\")\n",
    "    ax1.set_title(f'Weak Learner (Iteração {i+1})')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('yi')\n",
    "    ax1.axvline(r, c=\"k\", ls=\"--\")\n",
    "    \n",
    "    ax2.plot(x,y, 'o')\n",
    "    ax2.plot(xs, ys, 'r')\n",
    "    ax2.set_title(f'Previsão Final (Iteração {i+1})')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "\n",
    "    ax3.plot(x, ei, 'go')\n",
    "    ax3.set_title(f'Residuos (Iteração {i+1})')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('Residuals')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Boston\n",
    "\n",
    "Dataset com preços de imóveis em Boston\n",
    "\n",
    "\n",
    "#### Atributos\n",
    "- **CRIM** - Crime per capita\n",
    "- **ZN** - Proporção de área residencial\n",
    "- **INDUS** - Proporção de área industrial\n",
    "- **CHAS** - Charles River dummy variable\n",
    "- **NOX** -  Concentração de óxido nítrico (partes por 10 milhões)\n",
    "- **RM** - Média de cômodos por habitação\n",
    "- **AGE** - Proporção de casas/prédios construídos antes de 1940\n",
    "- **DIS** - Distância (ponderada) para centros de emprego\n",
    "- **RAD** - Índice de acessibilidade a vias centrais\n",
    "- **TAX** - Taxa de imposto\n",
    "- **PTRATIO** - Proporção número de professores/número de estudantes\n",
    "- **B** - 1000(Bk — 0.63)², onde Bk é a proporção de negros\n",
    "- **LSTAT** - Status da população\n",
    "\n",
    "#### Target\n",
    "- **MEDV** - Mediana do valor dos imóveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(regressor.feature_importances_.reshape(1, -1), columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EQM (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EQM (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    random_state=42\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Child Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg_Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.001,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de diabetes\n",
    "Dados de 442 pacientes de diabetes (idade, sexo, medidas de serum, ...), alem de uma variável-resposta de progressao da doença um ano depois\n",
    "\n",
    "#### Atributos\n",
    "- **Idade**\n",
    "- **Sexo**\n",
    "- **IMC**\n",
    "- **Pressão Sanguinea**\n",
    "- **S1**\n",
    "- **S2**\n",
    "- **S3**\n",
    "- **S4**\n",
    "- **S5**\n",
    "- **S6**\n",
    "\n",
    "\n",
    "#### Target\n",
    "Medida quantitativa de progressão da doença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "\n",
    "#### Atributos\n",
    "- Comprimento do sépalo\n",
    "- Largura do sépalo\n",
    "- Comprimento da pétala\n",
    "- Largura da pétala\n",
    "\n",
    "#### Target\n",
    "- Classe: Iris Setosa, Iris Versicolour e Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(objective = 'multi:softmax')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acurácia: {metrics.accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.adult()\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "model = xgb.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)\n",
    "pl.title(\"xgboost.plot_importance(model)\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model, importance_type=\"gain\")\n",
    "pl.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(500)\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_sample.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
